# Audio-data-processing

Audio data is ubiquitous today, from music streaming platforms to virtual assistants. Analyzing and processing audio requires a data manipulation and visualization techniques.

# Dataset Description

The audio data used in this project is the NSynth (Neural Synthesizer) dataset created by Google. It is a large-scale dataset for audio synthesis research which consists of over 300,000 musical notes, each with a unique combination of instrument, pitch, and timbre.

The dataset includes recordings from a diverse range of instruments, categorized into families like strings, brass, and mallets. Each audio sample is labelled with metadata, such as pitch, velocity, and instrument family.

---

# Project Summary

In this project, I have worked on the NSynth audio dataset, its preprocessing and analysis.

I performed various visualizations like waveforms and spectrogram heatmaps to understand the instrument distributions and extracted features like MFCCs to uncover valuable insights into audio structures and frequencies.

I also applied transformations like pitch shifting and time stretching to demonstrate audio augmentation techniques.
